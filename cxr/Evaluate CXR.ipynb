{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import DataParallel\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from concept_utils import DensenetCXRBottom, DensenetCXRTop\n",
    "from concept_utils import ConceptBank, get_concept_scores_mv_valid\n",
    "\n",
    "from data.dataset import ImageDataset  \n",
    "from model.classifier import Classifier  \n",
    "\n",
    "model_paths = {\"nih\": \"/path/projects/ptx/chexpert_models/nih/nih_sr_1\"}\n",
    "\n",
    "test_dfs = {\n",
    "            \"cxp\": \"/path/cxp/chexpert_full/splits/v0/test_df.csv\"\n",
    "}\n",
    "\n",
    "broden_path = {\n",
    "    \"nih\":\"/path/banks/concept_densenet_0.001_nih.pkl\",\n",
    "}\n",
    "model_ds = \"nih\"\n",
    "test_ds = \"cxp\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Test model')\n",
    "MODEL_PATH = model_paths[model_ds]\n",
    "CONCEPT_BANK_PATH = f\"./xr_concept_densenet_{model_ds}_on_{test_ds}.pkl\"\n",
    "IN_CSV_PATH = test_dfs[test_ds]\n",
    "BRODEN_CONCEPTS_PATH = broden_path[model_ds]\n",
    "\n",
    "parser.add_argument('--model_path', default=MODEL_PATH, metavar='MODEL_PATH',\n",
    "                    type=str, help=\"Path to the trained models\")\n",
    "parser.add_argument('--in_csv_path', default=IN_CSV_PATH, metavar='IN_CSV_PATH',\n",
    "                    type=str, help=\"Path to the input image path in csv\")\n",
    "parser.add_argument('--out_csv_path', default='test/test.csv',\n",
    "                    metavar='OUT_CSV_PATH', type=str,\n",
    "                    help=\"Path to the ouput predictions in csv\")\n",
    "parser.add_argument('-f', default='0', type=str, help=\"GPU indices \"\n",
    "                    \"comma separated, e.g. '0,1' \")\n",
    "parser.add_argument('--concept-bank-path', default=CONCEPT_BANK_PATH)\n",
    "parser.add_argument('--device', default=\"cuda\", type=str)\n",
    "\n",
    "if not os.path.exists('test'):\n",
    "    os.mkdir('test')\n",
    "args = parser.parse_args()\n",
    "std_pxs = np.array([0.229, 0.224, 0.225])\n",
    "mean_pxs = np.array([0.485, 0.456, 0.406])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(args.model_path, 'cfg.json')) as f:\n",
    "    cfg = edict(json.load(f))\n",
    "\n",
    "model = Classifier(cfg)\n",
    "model = DataParallel(model).to(args.device).eval()\n",
    "print(\"Model is initialized!!\")\n",
    "ckpt_path = os.path.join(args.model_path, 'best1.ckpt')\n",
    "ckpt = torch.load(ckpt_path, map_location=args.device)\n",
    "model.module.load_state_dict(ckpt['state_dict'])\n",
    "print(\"Model is loaded!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "model.eval()\n",
    "\n",
    "model_bottom, model_top = DensenetCXRBottom(model), DensenetCXRTop(model)\n",
    "model_bottom, model_top = model_bottom.eval(), model_top.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(IN_CSV_PATH)\n",
    "ds_sampled = ds[ds[\"Frontal/Lateral\"] == \"Lateral\"]\n",
    "ds_sampled.to_csv(\"./temp_df.csv\")\n",
    "dataloader_test = DataLoader(\n",
    "    ImageDataset(\"./temp_df.csv\", cfg, mode='valid', sample_n=110),\n",
    "    batch_size=1, num_workers=1,\n",
    "    drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.concept_bank_path, \"rb\") as f:\n",
    "    xr_bank = pickle.load(f)\n",
    "with open(BRODEN_CONCEPTS_PATH, \"rb\") as f:\n",
    "    concept_bank = pickle.load(f)\n",
    "n_broden = len(concept_bank)\n",
    "\n",
    "\n",
    "for c in xr_bank.keys():\n",
    "    if xr_bank[c][2] > .6:\n",
    "        concept_bank[c] = xr_bank[c]\n",
    "\n",
    "concept_bank = ConceptBank(concept_bank, args.device)\n",
    "print(len(concept_bank.concept_names))\n",
    "target_concepts = concept_bank.concept_names[n_broden:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 0\n",
    "trues = 0\n",
    "all_rows = []\n",
    "for img, path, label in tqdm(dataloader_test):\n",
    "    examples += 1\n",
    "    img = img.to(args.device)\n",
    "    label = label.to(args.device)\n",
    "    embedding = model_bottom(img)\n",
    "    out = model_top(embedding)\n",
    "    prob = torch.sigmoid(out.view(-1)).cpu().detach().numpy()\n",
    "    pred = (prob > 0.5).astype(np.int)\n",
    "\n",
    "    if label.cpu().numpy()[0] == pred:\n",
    "        trues+=1\n",
    "        print(\"true\")\n",
    "        continue\n",
    "    \n",
    "    opt_result = get_concept_scores_mv_valid(img, label, \n",
    "                                         concept_bank, \n",
    "                                         model_bottom, model_top,\n",
    "                                         alpha=1e-1, beta=1e-2, lr=1e-1,\n",
    "                                         enforce_validity=True, momentum=0.9)\n",
    "    top5_bottom5 = opt_result.concept_scores_list[:5] + opt_result.concept_scores_list[-5:]\n",
    "    row = ds[ds.Path == path[0]].copy()\n",
    "    for c in target_concepts:\n",
    "        row[f\"{c}-Top3\"] = (c in opt_result.concept_scores_list[:3])\n",
    "        row[f\"{c}-Bottom3\"] = (c in opt_result.concept_scores_list[-3:])\n",
    "        row[f\"{c}-Order\"] = opt_result.concept_scores_list.index(c)\n",
    "    all_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.groupby([\"Lateral-Bottom3\", \"Frontal/Lateral\"]).mean()[\"Lateral-Order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.groupby([\"Lateral-Bottom3\", \"Frontal/Lateral\"]).count()[\"Lateral-Order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.groupby([\"View Position_AP-Top3\", \"Frontal/Lateral\"]).mean()[\"View Position_AP-Order\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv(IN_CSV_PATH)\n",
    "ds_sampled = ds[ds[\"Frontal/Lateral\"] != \"Lateral\"]\n",
    "ds_sampled.to_csv(\"./temp_df.csv\")\n",
    "dataloader_test = DataLoader(\n",
    "    ImageDataset(\"./temp_df.csv\", cfg, mode='valid', sample_n=110),\n",
    "    batch_size=1, num_workers=1,\n",
    "    drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "examples = 0\n",
    "for img, path, label in tqdm(dataloader_test):\n",
    "    ax = axs[examples]\n",
    "    img = img.to(args.device)\n",
    "    label = label.to(args.device)\n",
    "    ax.imshow(img[0].cpu().permute(1,2,0).numpy()*std_pxs + mean_pxs)\n",
    "    ax.axis(\"off\")\n",
    "    examples += 1\n",
    "    if examples == 4:\n",
    "        break\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../paper_figures/cxr/frontal_view.png\")\n",
    "plt.show(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(IN_CSV_PATH)\n",
    "ds_sampled = ds[ds[\"Frontal/Lateral\"] == \"Lateral\"]\n",
    "ds_sampled.to_csv(\"./temp_df.csv\")\n",
    "dataloader_test = DataLoader(\n",
    "    ImageDataset(\"./temp_df.csv\", cfg, mode='valid', sample_n=110),\n",
    "    batch_size=1, num_workers=1,\n",
    "    drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "examples = 0\n",
    "for img, path, label in tqdm(dataloader_test):\n",
    "    ax = axs[examples]\n",
    "    img = img.to(args.device)\n",
    "    label = label.to(args.device)\n",
    "    ax.imshow(img[0].cpu().permute(1,2,0).numpy()*std_pxs + mean_pxs)\n",
    "    ax.axis(\"off\")\n",
    "    examples += 1\n",
    "    if examples == 4:\n",
    "        break\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../paper_figures/cxr/lateral_view.png\")\n",
    "plt.show(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
