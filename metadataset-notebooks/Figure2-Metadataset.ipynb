{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from model_utils import get_model_parts\n",
    "from argparse import Namespace \n",
    "from concept_utils import get_concept_scores_mv_valid, ConceptBank, EasyDict\n",
    "from skimage import io\n",
    "import glob\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_root = \"/path/dataset/metadataset/MetaDataset/subsets\"\n",
    "im2node = \"/path/metadataset-concepts/MetaDataset-Distribution-Shift/generate_dataset/meta_data/img_to_node.pkl\"\n",
    "with open(im2node, \"rb\") as f: \n",
    "    im2node = pickle.load(f)\n",
    "\n",
    "args = Namespace()\n",
    "args.model_name = \"resnet\"\n",
    "args.input_size = 224\n",
    "args.batch_size = 8\n",
    "args.SEED = 4\n",
    "args.num_workers = 4\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.bank_path = '/path/conceptual-explanations/banks/concept_resnet_170.pkl'\n",
    "mean_pxs = np.array([0.485, 0.456, 0.406])\n",
    "std_pxs = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(args.input_size),\n",
    "    transforms.CenterCrop(args.input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_pxs, std_pxs)\n",
    "])\n",
    "\n",
    "experiment_root = f'/path/outputs/conceptualexplanations/metadataset/{args.model_name}'"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "control_folder = os.path.join(experiment_root, f\"control\")\n",
    "experiments = os.listdir(experiment_root)\n",
    "\n",
    "exp_concepts = [\"sand\", \"paper\", \"water\", \"snow\", \"bed\", \"keyboard\", \"cabinet\",\n",
    "               \"carpet\", \"horse\", \"door\", \"paper\", \"fence\", \"tree\",\n",
    "                \"computer\", \"grass\", \"branch\", \"car\", \"building\", \"plate\",\n",
    "                \"bush\", \"book\"]\n",
    "\n",
    "all_concepts = pickle.load(open(args.bank_path, 'rb'))\n",
    "concept_bank = ConceptBank(all_concepts, args.device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DriftDataset():\n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the observation based on an index. Ex. dataset[0] will return the first element from the dataset, in this case the image and the label.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = self.images[idx]\n",
    "        image = io.imread(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "def get_drift_dataset(experiment_folder, data_root, drift_dist, exclude_concepts, class_name, transforms, take_diff=True,\n",
    "                     seed=1, n_max_images=50):\n",
    "    \n",
    "    drift_dist_args = drift_dist.split(\"(\")\n",
    "    print(drift_dist_args)\n",
    "    \n",
    "    if len(drift_dist_args) > 1:\n",
    "        drift_folder = os.path.join(data_root, drift_dist_args[0], drift_dist)\n",
    "        drift_ims = glob.glob(os.path.join(drift_folder, \"*.jpg\"), recursive=False)\n",
    "    else:\n",
    "        drift_folder = os.path.join(data_root, drift_dist_args[0])\n",
    "        drift_ims = glob.glob(os.path.join(drift_folder, \"**/*.jpg\"), recursive=True)\n",
    "    \n",
    "    train_folder = os.path.join(experiment_folder, \"train\", class_name)\n",
    "    train_ims = os.listdir(train_folder)\n",
    "    common_ims = set([im_path for im_path in drift_ims if (im_path.split(\"/\")[-1] in train_ims)])\n",
    "\n",
    "    exclude_concept_ims = []\n",
    "    print(f\"Excluding images for : {exclude_concepts}\")\n",
    "    for c in exclude_concepts:\n",
    "        if c == drift_dist:\n",
    "            continue\n",
    "        concept_folder = os.path.join(data_root, c.split(\"(\")[0], c)\n",
    "        concept_ims = os.listdir(concept_folder)\n",
    "        exclude_concept_ims.extend(concept_ims)\n",
    "        print(len(concept_ims))\n",
    "    \n",
    "    exclude_ims = set([im_path for im_path in drift_ims if im_path.split(\"/\")[-1] in exclude_concept_ims])\n",
    "    if take_diff:\n",
    "        drift_ims = list(set(drift_ims).difference(common_ims))\n",
    "    \n",
    "    drift_ims = list(set(drift_ims).difference(exclude_ims))\n",
    "    #print(f\"{len(drift_ims)} test images for {drift_dist}. Common ims w/training: {len(common_ims)}. Others: {len(exclude_ims)}\")\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(drift_ims)\n",
    "    drift_ims = drift_ims[:n_max_images]\n",
    "    drift_ims = [path for path in drift_ims if len(io.imread(path).shape) > 2]\n",
    "    drift_ds = DriftDataset(drift_ims, transforms)\n",
    "    print(f\"Final image count: {len(drift_ims[:n_max_images])}\")\n",
    "    return drift_ds\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eval_modes = [\"mistakes\"]\n",
    "batch_sizes = [1]\n",
    "experiments = [\"bird(sand)\", \"dog(snow)\", \"dog(bed)\", \"dog(water)\", \"dog(horse)\", \"cat(cabinet)\", \"cat(bed)\"]\n",
    "\n",
    "\n",
    "all_out = []\n",
    "# Control model\n",
    "control_folder = os.path.join(experiment_root, \"control\")\n",
    "model_control = torch.load(open(os.path.join(control_folder, \"result\", \"confounded-model.pt\"), \"rb\"))\n",
    "model_bottom_control, model_top_control = get_model_parts(model_control, args.model_name)\n",
    "model_bottom_control.eval()\n",
    "model_top_control.eval()\n",
    "all_concept_names = concept_bank.concept_names.copy()\n",
    "\n",
    "for experiment in experiments:\n",
    "\n",
    "    if len(experiment.split(\"-\")) > 1:\n",
    "        continue\n",
    "    experiment_folder = os.path.join(experiment_root, experiment)\n",
    "    try:\n",
    "        with open(os.path.join(experiment_folder, \"result\", \"concept_config.pkl\"), \"rb\") as f:\n",
    "            concept_config = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(e, experiment)\n",
    "        continue\n",
    "    true_concepts = []\n",
    "    for cl in concept_config[\"in_distributions\"]:\n",
    "        if \"(\" in cl:\n",
    "            class_name = cl.split(\"(\")[0]\n",
    "            true_concept = cl.split(\"(\")[-1][:-1]    \n",
    "            if true_concept == 'branch':\n",
    "                true_concept = 'tree'\n",
    "            true_concepts.append(true_concept)\n",
    "    \n",
    "    if len(true_concepts) != 1:\n",
    "        continue\n",
    "    \n",
    "    are_invalid_concepts = np.array([((c not in exp_concepts) or (c not in concept_bank.concept_names)) for c in true_concepts])\n",
    "    if np.any(are_invalid_concepts):\n",
    "        continue\n",
    "    \n",
    "    dists_to_remove = [c for c in concept_config[\"in_distributions\"] if \"(\" in c]\n",
    "    print(f\"Animal: {class_name}, True Concept: {true_concepts}\")\n",
    "    \n",
    "    \n",
    "    # Get models \n",
    "    model_ft = torch.load(open(os.path.join(experiment_folder, \"result\", \"confounded-model.pt\"), \"rb\"))\n",
    "    # Model to test\n",
    "    model_bottom, model_top = get_model_parts(model_ft, args.model_name)\n",
    "    model_bottom.eval()\n",
    "    model_top.eval()\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(os.path.join(experiment_folder, \"train\"), data_transforms)\n",
    "    class_idx = train_dataset.class_to_idx[class_name]\n",
    "    labels_orig = torch.tensor(class_idx).long().view(1).to(args.device)        \n",
    "    for batch_size in batch_sizes:\n",
    "        drift_ds = get_drift_dataset(experiment_folder, data_root, class_name, dists_to_remove,\n",
    "                                     class_name, data_transforms, take_diff=True, seed=3)\n",
    "        \n",
    "        dataloaders_drift = torch.utils.data.DataLoader(drift_ds, batch_size=50, shuffle=False, num_workers=args.num_workers)\n",
    "        for eval_mode in eval_modes:\n",
    "            batch_inputs = None\n",
    "            batch_labels = None\n",
    "            for inputs in dataloaders_drift: \n",
    "                inputs = inputs.to(args.device)\n",
    "                labels = labels_orig.repeat(inputs.shape[0])\n",
    "                label_mask = (labels == class_idx)\n",
    "                if label_mask.float().sum() < 1:\n",
    "                    continue\n",
    "                if eval_mode == \"mistakes\":\n",
    "                    preds = model_top(model_bottom(inputs)).argmax(dim=1)\n",
    "                    label_mask = (label_mask & (preds.squeeze() != labels.squeeze()))\n",
    "                    if label_mask.float().sum() < 1:\n",
    "                        continue\n",
    "                \n",
    "                if batch_inputs is None:\n",
    "                    batch_inputs, batch_labels = inputs[label_mask], labels[label_mask]\n",
    "                else:\n",
    "                    batch_inputs = torch.cat([batch_inputs, inputs[label_mask]], dim=0)\n",
    "                    batch_labels = torch.cat([batch_labels, labels[label_mask]], dim=0)\n",
    "                                              \n",
    "            score_dict = {name: [] for name in concept_bank.concept_names}\n",
    "            control_score_dict = {name: [] for name in concept_bank.concept_names}\n",
    "            random_score_dict = {name: [] for name in concept_bank.concept_names}\n",
    "            sample_size = max(batch_inputs.shape[0] - (batch_inputs.shape[0] % batch_size), (batch_inputs.shape[0] % batch_size))\n",
    "            tqdm_iterator = tqdm(range(max(1, sample_size // batch_size)))\n",
    "            \n",
    "            for k in tqdm_iterator:                \n",
    "                batch_X = batch_inputs[k*batch_size : (k+1)*batch_size]\n",
    "                batch_Y = batch_labels[k*batch_size : (k+1)*batch_size]\n",
    "\n",
    "                opt_result = get_concept_scores_mv_valid(batch_X, batch_Y, \n",
    "                                                         concept_bank, \n",
    "                                                         model_bottom, model_top,\n",
    "                                                         alpha=1e-2, beta=1e-1, lr=1e-2,\n",
    "                                                         enforce_validity=True, momentum=0.9)\n",
    "                \n",
    "                control_opt_result = get_concept_scores_mv_valid(batch_X, batch_Y, \n",
    "                                                         concept_bank, \n",
    "                                                         model_bottom_control, model_top_control,\n",
    "                                                         alpha=1e-2, beta=1e-1, lr=1e-2,\n",
    "                                                         enforce_validity=True, momentum=0.9)\n",
    "                np.random.shuffle(all_concept_names)\n",
    "                random_result = EasyDict({\n",
    "                    \"concept_scores_list\": all_concept_names\n",
    "                    \n",
    "                })\n",
    "                for i, name in enumerate(opt_result.concept_scores_list): \n",
    "                    score_dict[name].append(i)\n",
    "                for i, name in enumerate(control_opt_result.concept_scores_list): \n",
    "                    control_score_dict[name].append(i)\n",
    "                for i, name in enumerate(random_result.concept_scores_list): \n",
    "                    random_score_dict[name].append(i)\n",
    "                score_arr = np.array(score_dict[true_concepts[0]])\n",
    "                control_score_arr = np.array(control_score_dict[true_concepts[0]])\n",
    "                desc = f\"Mean: {np.mean(score_arr):.2f}, Top3:{(score_arr < 3).mean()}\"\n",
    "                tqdm_iterator.set_description(desc)\n",
    "            \n",
    "            print(score_dict[true_concepts[0]])\n",
    "            print(f\"Top3: {(np.array(score_dict[true_concepts[0]])<3).mean()}\")\n",
    "            mean_score_dict = {}\n",
    "            for k in score_dict.keys(): \n",
    "                mean_score_dict[k] = np.mean(score_dict[k])\n",
    "            \n",
    "            ordered = sorted(concept_bank.concept_names, key=mean_score_dict.get)\n",
    "            control_score = (np.array(control_score_dict[true_concepts[0]])<3).mean()\n",
    "            random_score = (np.array(random_score_dict[true_concepts[0]])<3).mean()\n",
    "            ces_top3_score =  (np.array(score_dict[true_concepts[0]])<3).mean()\n",
    "            \n",
    "            all_out.append({\n",
    "                \"experiment\": experiment,\n",
    "                \"target\": true_concepts,\n",
    "                \"batch_size\": batch_size,\n",
    "                \"eval_mode\": eval_mode,\n",
    "                \"sample_size\": sample_size,\n",
    "                \"top5_concepts\": ordered[:5],\n",
    "                \"overall_rank\": ordered.index(true_concept)+1,\n",
    "                \"Top3\": ces_top3_score,\n",
    "                \"Top3-Control\": control_score,\n",
    "                \"Top3-Random\": random_score\n",
    "            })\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            x_names = ['Random', 'CCE (Control)', 'CCE']\n",
    "            y_vals = [3/150, control_score, ces_top3_score]\n",
    "            plt.bar(x_names, y_vals, color=['silver','gray', 'black'])\n",
    "            plt.yticks(fontname='DejaVu Sans', fontsize=20)\n",
    "            plt.xticks(fontname='DejaVu Sans', fontsize=20)\n",
    "            plt.ylim([0, 1])\n",
    "            plt.ylabel('Fraction of samples\\n concept is in top 3', fontname='DejaVu Sans', fontsize=20)\n",
    "            plt.title('\"{}\" correlated with \"{}\"'.format(class_name.title(), true_concepts[0].title()), fontsize=20, fontname='Arial')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"./paper_figures/figure3/fig3_{experiment}_{args.model_name}.png\")\n",
    "            plt.savefig(f\"./paper_figures/figure3/fig3_{experiment}_{args.model_name}.pdf\")\n",
    "            plt.show()\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}