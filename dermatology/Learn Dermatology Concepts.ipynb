{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from model_utils import get_embedding, get_trained_model, get_model_parts\n",
    "from concept_utils import get_concept_scores_mv_valid\n",
    "from concept_utils import learn_concept\n",
    "from data_utils import SkinDataset\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import torch\n",
    "from imagecorruptions import corrupt, get_corruption_names\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def config():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--fitzpatrick-csv-path\", default=\"./dataset/fitzpatrick17k.csv\", type=str)\n",
    "    parser.add_argument(\"--model-dir\", default=\"/path/outputs/fitzpatrick/\", type=str)\n",
    "    parser.add_argument(\"--concept-bank-path\", default=\"./banks/concept_resnet_170.pkl\", type=str)\n",
    "    parser.add_argument(\"--data-dir\", default=\"/path/dataset/data/finalfitz17k\", type=str)\n",
    "    parser.add_argument(\"--device\", default=\"cuda\", type=str)\n",
    "    parser.add_argument(\"--batch-size\", default=32, type=int)\n",
    "    parser.add_argument(\"--num-workers\", default=4, type=int)\n",
    "    parser.add_argument(\"--n-samples\", default=40, type=int, help=\"Number of positive/negatives for learning the concept.\")\n",
    "    parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n",
    "    parser.add_argument(\"--model-type\", default=\"resnet\", type=str)\n",
    "    parser.add_argument(\"--C\", default=0.01, type=float)\n",
    "    parser.add_argument(\"-f\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "args = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "model_bottom, _ = get_model_parts(model_name=args.model_type, model=model_ft)\n",
    "model_bottom = model_bottom.to(args.device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "derma_concepts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin Color Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(args.fitzpatrick_csv_path)\n",
    "df[\"low\"] = df['label'].astype('category').cat.codes\n",
    "df[\"mid\"] = df['nine_partition_label'].astype('category').cat.codes\n",
    "df[\"high\"] = df['three_partition_label'].astype('category').cat.codes\n",
    "df[\"hasher\"] = df[\"md5hash\"]\n",
    "torch.manual_seed(args.seed)\n",
    "ds_transforms = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(size=256),\n",
    "                transforms.CenterCrop(size=224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "pos_ds = SkinDataset(df[((df.fitzpatrick == 5) | (df.fitzpatrick == 6)) & (df.low != 1)],\n",
    "                     root_dir=args.data_dir,\n",
    "                     transform=ds_transforms)\n",
    "pos_loader = torch.utils.data.DataLoader(pos_ds,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args.num_workers)\n",
    "\n",
    "neg_ds = SkinDataset(df[((df.fitzpatrick == 1) | (df.fitzpatrick == 2)) & (df.low != 1)],\n",
    "                     root_dir=args.data_dir,\n",
    "                     transform=ds_transforms)\n",
    "\n",
    "neg_loader = torch.utils.data.DataLoader(neg_ds,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args.num_workers)\n",
    "\n",
    "# Get model activations\n",
    "pos_act, pos_fps = get_embedding(pos_loader, model_bottom, n_samples=args.n_samples, device=args.device)\n",
    "neg_act, neg_fps = get_embedding(neg_loader, model_bottom, n_samples=args.n_samples, device=args.device)\n",
    "activations = torch.cat([pos_act, neg_act], dim=0)\n",
    "c_labels = torch.cat([torch.ones(args.n_samples), torch.zeros(args.n_samples)], dim=0)\n",
    "activations, c_labels = activations.cpu().numpy(), c_labels.numpy()\n",
    "concept_info = learn_concept(activations, c_labels, args, C=args.C)\n",
    "derma_concepts[\"dark-skin-color\"] = concept_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Quality Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EasyDataset():\n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the observation based on an index. Ex. dataset[0] will return the first element from the dataset, in this case the image and the label.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = self.images[idx]\n",
    "        image = io.imread(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        res = {\"image\": image, \n",
    "              \"fitzpatrick\": -1}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.groupby(\"fitzpatrick\").sample(n=30, random_state=1).sample(args.n_samples*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "pos_ds = SkinDataset(df1,\n",
    "                     root_dir=args.data_dir,\n",
    "                     transform=transforms.Compose([\n",
    "                         transforms.ToPILImage(),\n",
    "                         transforms.Resize(size=224*4),\n",
    "                         transforms.CenterCrop(size=224),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                     ]))\n",
    "\n",
    "\n",
    "pos_loader = torch.utils.data.DataLoader(pos_ds,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args.num_workers)\n",
    "\n",
    "neg_ds = SkinDataset(df1,\n",
    "                     root_dir=args.data_dir,\n",
    "                     transform=ds_transforms)\n",
    "\n",
    "neg_loader = torch.utils.data.DataLoader(neg_ds,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args.num_workers)\n",
    "\n",
    "# Get model activations\n",
    "pos_act, pos_fps = get_embedding(pos_loader, model_bottom, n_samples=args.n_samples, device=args.device)\n",
    "neg_act, neg_fps = get_embedding(neg_loader, model_bottom, n_samples=args.n_samples, device=args.device)\n",
    "activations = torch.cat([pos_act, neg_act], dim=0)\n",
    "c_labels = torch.cat([torch.ones(args.n_samples), torch.zeros(args.n_samples)], dim=0)\n",
    "activations, c_labels = activations.cpu().numpy(), c_labels.numpy()\n",
    "concept_info = learn_concept(activations, c_labels, args, C=args.C)\n",
    "derma_concepts[\"zoom\"] = concept_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CorruptedSkinDataset():\n",
    "    def __init__(self, df, root_dir, transform=None,\n",
    "                corruption_name=\"brightness\", severity=2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.corruption_name = corruption_name\n",
    "        self.severity = severity\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                f\"{self.df.loc[self.df.index[idx], 'hasher']}.jpg\")\n",
    "        image = io.imread(img_name)\n",
    "        image = corrupt(image, corruption_name=self.corruption_name, severity=self.severity)\n",
    "        if(len(image.shape) < 3):\n",
    "            image = skimage.color.gray2rgb(image)\n",
    "\n",
    "        hasher = self.df.loc[self.df.index[idx], 'hasher']\n",
    "        high = self.df.loc[self.df.index[idx], 'high']\n",
    "        mid = self.df.loc[self.df.index[idx], 'mid']\n",
    "        low = self.df.loc[self.df.index[idx], 'low']\n",
    "        fitzpatrick = self.df.loc[self.df.index[idx], 'fitzpatrick']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {\n",
    "                    'image': image,\n",
    "                    'high': high,\n",
    "                    'mid': mid,\n",
    "                    'low': low,\n",
    "                    'hasher': hasher,\n",
    "                    'fitzpatrick': fitzpatrick\n",
    "                }\n",
    "        return sample\n",
    "\n",
    "\n",
    "corruptions = {\"zoom_blur\": 2,\n",
    "              \"contrast\": 2,\n",
    "              \"defocus_blur\": 3,\n",
    "              \"brightness\": 3,\n",
    "              \"motion_blur\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for corruption in corruptions.keys():\n",
    "    df1 = df.sample(2*args.n_samples)\n",
    "    pos_ds = CorruptedSkinDataset(df1,\n",
    "                                  root_dir=args.data_dir,\n",
    "                                  transform=ds_transforms,\n",
    "                                  corruption_name=corruption,\n",
    "                                  severity=corruptions[corruption])\n",
    "    \n",
    "    pos_loader = torch.utils.data.DataLoader(pos_ds,\n",
    "                                             batch_size=args.batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=args.num_workers)\n",
    "    \n",
    "    neg_ds = SkinDataset(df1,\n",
    "                         root_dir=args.data_dir,\n",
    "                         transform=ds_transforms)\n",
    "    \n",
    "    neg_loader = torch.utils.data.DataLoader(neg_ds,\n",
    "                                             batch_size=args.batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=args.num_workers)\n",
    "    \n",
    "    # Get model activations\n",
    "    pos_act, pos_fps = get_embedding(pos_loader, model_bottom, n_samples=args.n_samples, device=args.device)\n",
    "    neg_act, neg_fps = get_embedding(neg_loader, model_bottom, n_samples=args.n_samples, device=args.device)\n",
    "    activations = torch.cat([pos_act, neg_act], dim=0)\n",
    "    c_labels = torch.cat([torch.ones(args.n_samples), torch.zeros(args.n_samples)], dim=0)\n",
    "    activations, c_labels = activations.cpu().numpy(), c_labels.numpy()\n",
    "    concept_info = learn_concept(activations, c_labels, args, C=args.C)\n",
    "    derma_concepts[corruption] = concept_info\n",
    "    print(corruption, corruptions[corruption], concept_info[1], concept_info[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EasyDataset():\n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the observation based on an index. Ex. dataset[0] will return the first element from the dataset, in this case the image and the label.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = self.images[idx]\n",
    "        image = io.imread(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        res = {\"image\": image, \n",
    "              \"fitzpatrick\": -1}\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hair_images_folder = \"./hair_images/\" \n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hair_ims = [os.path.join(hair_images_folder, p) for p in os.listdir(hair_images_folder)]\n",
    "hair_n_samples = 10\n",
    "pos_ds = EasyDataset(hair_ims, transform=ds_transforms)\n",
    "\n",
    "pos_loader = torch.utils.data.DataLoader(pos_ds,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args.num_workers)\n",
    "\n",
    "neg_ds = SkinDataset(df.sample(200),\n",
    "                     root_dir=args.data_dir,\n",
    "                     transform=ds_transforms)\n",
    "\n",
    "neg_loader = torch.utils.data.DataLoader(neg_ds,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args.num_workers)\n",
    "\n",
    "# Get model activations\n",
    "pos_act, pos_fps = get_embedding(pos_loader, model_bottom, n_samples=len(hair_ims), device=args.device)\n",
    "neg_act, neg_fps = get_embedding(neg_loader, model_bottom, n_samples=len(hair_ims), device=args.device)\n",
    "\n",
    "print(neg_act.shape)\n",
    "\n",
    "X_train = torch.cat([pos_act[:hair_n_samples], neg_act[:hair_n_samples]], dim=0).cpu().numpy()\n",
    "X_test = torch.cat([pos_act[hair_n_samples:len(hair_ims)], neg_act[hair_n_samples:len(hair_ims)]], dim=0).cpu().numpy()\n",
    "y_train = torch.cat([torch.ones(hair_n_samples), torch.zeros(hair_n_samples)], dim=0).numpy()\n",
    "y_test = torch.cat([torch.ones(len(hair_ims)-hair_n_samples), torch.zeros(len(hair_ims)-hair_n_samples)], dim=0).numpy()\n",
    "\n",
    "\n",
    "svm = SVC(kernel=\"linear\", C=0.001, probability=False)\n",
    "svm.fit(X_train, y_train)\n",
    "train_acc = svm.score(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "print(f\"Accuracy - Training: {train_acc}, Test: {test_acc}\")\n",
    "\n",
    "train_margin = ((np.dot(svm.coef_, X_train.T) + svm.intercept_) / np.linalg.norm(svm.coef_)).T\n",
    "\n",
    "margin_info = {\"max\": np.max(train_margin),\n",
    "               \"min\": np.min(train_margin),\n",
    "               \"pos_mean\": np.mean(train_margin[train_margin > 0]),\n",
    "               \"pos_std\": np.std(train_margin[train_margin > 0]),\n",
    "               \"neg_mean\": np.mean(train_margin[train_margin < 0]),\n",
    "               \"neg_std\": np.std(train_margin[train_margin < 0]),\n",
    "               \"q_90\": np.quantile(train_margin, 0.9),\n",
    "               \"q_10\": np.quantile(train_margin, 0.1)\n",
    "               }\n",
    "# print test accuracy\n",
    "derma_concepts[\"derma-hair\"] = concept_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(args.concept_bank_path, \"rb\") as f:\n",
    "    concept_bank = pickle.load(f)\n",
    "\n",
    "for derm_concept, info in derma_concepts.items():\n",
    "    print(derm_concept)\n",
    "    assert derm_concept not in concept_bank\n",
    "    concept_bank[derm_concept] = info\n",
    "\n",
    "with open(\"./derma_concepts_resnet_new.pkl\", \"wb\") as f:\n",
    "    pickle.dump(concept_bank, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "corruptions = {\"zoom_blur\": 2,\n",
    "              \"contrast\": 2,\n",
    "              \"defocus_blur\": 3,\n",
    "              \"brightness\": 3,\n",
    "              \"motion_blur\": 3}\n",
    "df1 = df.groupby(\"fitzpatrick\").sample(n=30, random_state=3).sample(args.n_samples*2)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(len(corruptions.keys()), 5, figsize=(20, 4*len(corruptions)))\n",
    "img_name = os.path.join(args.data_dir, f\"{df1.loc[df1.index[1], 'hasher']}.jpg\")\n",
    "image = io.imread(img_name)\n",
    "for i, corruption in enumerate(corruptions.keys()):\n",
    "    for j, severity in enumerate(range(1, 6)):\n",
    "        ax = axs[i, j]\n",
    "        ax.axis(\"off\")\n",
    "        if severity == 1:\n",
    "            ax.imshow(image)\n",
    "            ax.set_title(f\"Original\")\n",
    "        else:\n",
    "            corr_img = corrupt(image, severity=severity, corruption_name=corruption)\n",
    "            ax.imshow(corr_img)\n",
    "            ax.set_title(f\"{corruption}:{severity}\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"./concept_demonstrations.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
