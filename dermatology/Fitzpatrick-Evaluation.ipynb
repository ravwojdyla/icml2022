{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bBB7-mHqdh96"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from model_utils import get_trained_model, get_model_parts\n",
    "from concept_utils import get_concept_scores_mv_valid, ConceptBank\n",
    "from data_utils import SkinDataset\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "def config():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--fitzpatrick-csv-path\", default=\"../../dataset/fitzpatrick17k.csv\", type=str)\n",
    "    parser.add_argument(\"--pretrained-model-path\",\n",
    "                        default=\"model-path_resnet_25_random-holdout_low_0.pth\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--model-dir\", default=\"/path/outputs/fitzpatrick/\", type=str)\n",
    "    parser.add_argument(\"--concept-bank-path\", default=\"./derma_concepts_resnet_new.pkl\", type=str)\n",
    "    parser.add_argument(\"--data-dir\", default=\"/path/data/finalfitz17k\", type=str)\n",
    "    parser.add_argument(\"--device\", default=\"cuda\", type=str)\n",
    "    parser.add_argument(\"--batch-size\", default=32, type=int)\n",
    "    parser.add_argument(\"--num-workers\", default=4, type=int)\n",
    "    parser.add_argument(\"--n-samples\", default=100, type=int, help=\"Number of positive/negatives for learning the concept.\")\n",
    "    parser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed\")\n",
    "    parser.add_argument(\"--model-type\", default=\"resnet\", type=str)\n",
    "    parser.add_argument(\"-f\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "args = config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "w2m9r4JvgjZb"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.fitzpatrick_csv_path)\n",
    "df[\"low\"] = df['label'].astype('category').cat.codes\n",
    "df[\"mid\"] = df['nine_partition_label'].astype('category').cat.codes\n",
    "df[\"high\"] = df['three_partition_label'].astype('category').cat.codes\n",
    "df[\"hasher\"] = df[\"md5hash\"]\n",
    "torch.manual_seed(args.seed)\n",
    "std_pxs = np.array([0.229, 0.224, 0.225])\n",
    "mean_pxs = np.array([0.485, 0.456, 0.406])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Uy1HfkfQcyLv",
    "outputId": "54744fff-5031-42e3-eb15-2c072a11ade5"
   },
   "outputs": [],
   "source": [
    "all_concepts = pickle.load(open(args.concept_bank_path, 'rb'))\n",
    "concept_bank = ConceptBank(all_concepts, args.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Images where Transformations can explain model mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scenarios = []\n",
    "for i in range(1):\n",
    "    scenarios.append({\"path\": f\"random-holdout_low_{i}\",\n",
    "                      \"df\": df[((df.fitzpatrick == 5) | (df.fitzpatrick == 6)) & (df.low == 6)],\n",
    "                      \"tag\": f\"skin-type-bias-{i}\"})\n",
    "\n",
    "concept_name = \"dark-skin-color\"\n",
    "\n",
    "for scenario in scenarios[:1]:\n",
    "    res = []\n",
    "    flip_list, ess = [], []\n",
    "    model_path = os.path.join(args.model_dir, f\"model-path_{args.model_type}_25_{scenario['path']}.pth\")\n",
    "    model_ft = get_trained_model(args.model_type, model_path)\n",
    "    model_ft = model_ft.to(args.device)\n",
    "    model_bottom, model_top = get_model_parts(model_name=args.model_type, model=model_ft)\n",
    "    model_bottom = model_bottom.to(args.device)\n",
    "    model_bottom.eval(), model_top.eval()\n",
    "    \n",
    "    test_df = scenario[\"df\"]\n",
    "    test_ds = SkinDataset(test_df,\n",
    "                          root_dir=args.data_dir,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToPILImage(),\n",
    "                              transforms.Resize(size=256),\n",
    "                              transforms.CenterCrop(size=224),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize(mean_pxs, std_pxs)\n",
    "                          ]))\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(test_ds,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=1)\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(loader)):\n",
    "        labels = batch[\"low\"]\n",
    "        inputs = batch[\"image\"].to(args.device)\n",
    "        \n",
    "        labels = labels.long().to(args.device)\n",
    "        orig_out = model_top(model_bottom(inputs))\n",
    "        pred = orig_out.argmax(dim=1)\n",
    "        prob = orig_out.max()\n",
    "        if pred == labels:\n",
    "            res.append(None)\n",
    "            flip_list.append(None)\n",
    "        else:\n",
    "            opt_result = get_concept_scores_mv_valid(inputs, labels, \n",
    "                                                     concept_bank, \n",
    "                                                     model_bottom, model_top,\n",
    "                                                     alpha=1e-2, beta=2e-2, lr=2e-2,\n",
    "                                                     enforce_validity=True, momentum=0.9,\n",
    "                                                     kappa=\"mean\")\n",
    "            res.append(opt_result.concept_scores_list.index(concept_name))\n",
    "    #break\n",
    "    top_ranks = np.array([a for a in res if a is not None])\n",
    "    bottom_ranks = len(concept_bank.concept_names)-top_ranks\n",
    "    print(res)\n",
    "    print(\"Bottom Ranks:\")\n",
    "    print(np.mean(bottom_ranks), np.median(bottom_ranks), np.quantile(bottom_ranks, 0.25),\n",
    "          np.quantile(bottom_ranks, 0.75),(bottom_ranks<6).mean())\n",
    "    print(\"Top Ranks:\")\n",
    "    print(np.mean(1+top_ranks), np.median(1+top_ranks), np.quantile(1+top_ranks, 0.25),\n",
    "          np.quantile(1+top_ranks, 0.75),(1+top_ranks<6).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Run Fitzpatrick.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
